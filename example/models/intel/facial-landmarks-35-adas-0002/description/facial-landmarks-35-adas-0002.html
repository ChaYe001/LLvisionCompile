<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
<link rel="stylesheet" href="../../intel_styles.css" type="text/css" />
</head>
<body>
<div id="banner">
    <div id="bannerblock">
      <img src="../../intel_logo.png" class="intellogo">
      <h1 class="title">Overview of OpenVINO&trade; toolkit Pre-trained Models</h1>
    </div>
  </div>
<div id="contentblock">
<h1 id="facial-landmarks-35-adas-0002">facial-landmarks-35-adas-0002</h1>
<h2 id="use-case-and-high-level-description">Use Case and High-Level Description</h2>
<p>This is a custom-architecture convolutional neural network for 35 facial landmarks estimation.</p>
<h2 id="example-and-landmarks-definition">Example and Landmarks Definition</h2>
<div class="figure">
<img src="./landmarks_illustration.png" />

</div>
<p>[Left Eye] <strong>p0, p1</strong>: corners of the eye, located on the boundary of the eyeball and the eyelid.</p>
<p>[Right Eye] <strong>p2, p3</strong>: corners of the eye, located on the boundary of the eyeball and the eyelid.</p>
<p>[Nose] <strong>p4</strong>: nose-tip point; <strong>p5</strong>: lowest point of the nasal septum; <strong>p6, p7</strong>: right-bottom and left-bottom of the nose wing.</p>
<p>[Mouth] <strong>p8, p9</strong>: mouth corners on the outer boundary of the lip; <strong>p10, p11</strong>: center points along the outer boundary of the lip.</p>
<p>[Left Eyebrow] <strong>p12</strong>: starting point of the upper boundary of the eyebrow; <strong>p13</strong>: mid-point of the upper arc of the eyebrow; <strong>p14</strong>: ending point of the upper boundary of the eyebrow.</p>
<p>[Right Eyebrow] <strong>p15</strong>: starting point of the upper boundary of the eyebrow; <strong>p16</strong>: mid-point of the upper arc of the eyebrow; <strong>p17</strong>: ending point of the upper boundary of the eyebrow.</p>
<p>[Face Contour] <strong>p26</strong>: chin center; <strong>p18, p34</strong>: upper points of the face contour aligned with the outer corners of the eyes; <strong>p19<sub>p25<strong>: boundary points, evenly distributed along the curve p18-p26; </strong>p27</sub>p33</strong>: boundary points, evenly distributed along the curve p26-p34.</p>
<h2 id="specification">Specification</h2>
<table>
<thead>
<tr class="header">
<th align="left">Metric</th>
<th align="left">Value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">GFlops</td>
<td align="left">0.042</td>
</tr>
<tr class="even">
<td align="left">MParams</td>
<td align="left">4.595</td>
</tr>
<tr class="odd">
<td align="left">Source framework</td>
<td align="left">Caffe*</td>
</tr>
</tbody>
</table>
<h2 id="validation-dataset">Validation Dataset</h2>
<p>A 1000-sample random subset of a large internal dataset containing images of 300 people with different facial expressions.</p>
<h2 id="validation-results">Validation Results</h2>
<p>The quality of landmarks' positions prediction is evaluated through the use of Normed Error (NE). The error for the i<sup>th</sup> sample has the form:</p>
<div class="figure">
<img src="./error_formula.png" />

</div>
<p>where N is the number of landmarks, <em>p</em>-hat and <em>p</em> are, correspondingly, the prediction and ground truth vectors of the k<sup>th</sup> landmark of the i<sup>th</sup> sample, and d<sub>i</sub> is the interocular distance for the i<sup>th</sup> sample.</p>
<table>
<thead>
<tr class="header">
<th align="left">Dataset</th>
<th align="left">Mean NE</th>
<th align="left">90<sup>th</sup> <a href="https://en.wikipedia.org/wiki/Percentile">Percentile</a> NE</th>
<th align="left"><a href="https://en.wikipedia.org/wiki/Standard_deviation">Standard deviation</a> of NE</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Internal dataset</td>
<td align="left">0.106</td>
<td align="left">0.143</td>
<td align="left">0.038</td>
</tr>
</tbody>
</table>
<h2 id="performance">Performance</h2>
<h2 id="inputs">Inputs</h2>
<ul>
<li>Blob in the format [BxCxHxW] where:</li>
<li>B - batch size</li>
<li>C - number of channels</li>
<li>H - image height</li>
<li>W - image width</li>
</ul>
<p>with the name <code>data</code> and the shape [1x3x60x60].</p>
<h2 id="outputs">Outputs</h2>
<p>The net outputs a blob with the shape: [1, 70], containing row-vector of 70 floating point values for 35 landmarks' normed coordinates in the form (x0, y0, x1, y1, ..., x34, y34).</p>
<p>Output layer name in Inference Engine format:</p>
<p><code>align_fc3</code></p>
<p>Output layer name in Caffe* format:</p>
<p><code>align_fc3</code></p>
<h2 id="legal-information">Legal Information</h2>
<p>[*] Other names and brands may be claimed as the property of others.</p>
</div>
</body>
</html>
